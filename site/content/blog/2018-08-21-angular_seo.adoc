---
author: Benjamin
cover: ohmyzsh-banner
date: '2018-08-30'
tags:
- SEO
- Angular
title: 'SEO et Single Page Application = ü§¨'
url: /2018/08/30/angular-seo/
---

Lorsque nous avons commenc√© √† d√©velopper WeGuide (https://weguide.fr), nous avons pas mal r√©fl√©chi √† quel framework utiliser pour r√©aliser la partie front et, du fait de notre exp√©rience, avons choisi Angular.
Nous connaissions les probl√®mes li√©s aux *Single Page Application* et au *SEO* mais nous pensions pouvoir les r√©soudre facilement par la suite.
Au final, c'√©tait un peu plus compliqu√© que pr√©vu et nous allons expliquer pourquoi dans la suite de cet article.

== Niveau facile : rendre les balises `meta` dynamiques

Angular fournit deux services afin de modifier les balises *HTML* destin√©es au *SEO* lors de l'affichage d'une page, `Meta` et `Title` qui, comme leur nom l'indique, permettent de modifier les balises `<meta>` et `<title>`.

Voici un exemple de service cr√©√© pour mettre √† jour les balises meta destin√©es √† l'OpenGraph et √† Twitter.

[source, javascript]
----
@Injectable({
  providedIn: 'root'
})
export class SeoService {

  constructor(private meta: Meta,
              private title: Title) {
  }

  generateTags(config) {
    // default values
    config = {
      title: 'Titre de la page',
      description: 'Description de la page par d√©faut',
      image: 'http://imagepardefaut.com',
      ...config
    };

    this.meta.updateTag({name: 'twitter:card', content: 'summary'});
    this.meta.updateTag({name: 'twitter:site', content: '@twitter'});
    this.meta.updateTag({name: 'twitter:title', content: config.title});
    this.meta.updateTag({name: 'twitter:description', content: config.description});
    this.meta.updateTag({name: 'twitter:image', content: config.image});

    this.meta.updateTag({property: 'og:type', content: 'article'});
    this.meta.updateTag({property: 'og:site_name', content: 'SiteName'});
    this.meta.updateTag({property: 'og:title', content: config.title});
    this.meta.updateTag({property: 'og:description', content: config.description});
    this.meta.updateTag({property: 'og:image', content: config.image});
    this.meta.updateTag({property: 'og:url', content: `https://monurl/`});

    this.title.setTitle(config.title);
    this.meta.addTags([
      {name: 'description', content: config.description},
      {name: 'keywords', content: config.description},
    ]);
  }
}
----

== Niveau moyen : g√©n√©rer un sitemap dynamiquement

Une autre partie du SEO indispensable est le sitemap.
Il permet aux robots de savoir exactement quelles pages indexer.
Probl√®me, sur une application comme WeGuide, nous ne pouvons pas √©crire ce fichier en dur, en effet, des nouveaux guides cr√©√©ent leur profil tous les jours sur la plateforme, ce qui veut dire, une nouvelle url en plus √† indexer.

Pour remedier √† cela c'est assez simple, il faut que le fichier soit dynamique et g√©n√©r√© √† la vol√©e par votre serveur.
Pour faire cela, il suffit de servir une route `/sitemap` qui retourne un fichier *XML* g√©n√©r√© √† l'aide d'appel aux diff√©rents services de votre application.

Voici un exemple sur une application *Spring Boot* en *Kotlin*

[source, java]
----
@Component
class SitemapView(@Autowired val sitemapService: SitemapService) : AbstractView() {
    override fun renderMergedOutputModel(model: MutableMap<String, Any>?,
                                         request: HttpServletRequest?,
                                         response: HttpServletResponse?) {
        response?.contentType = APPLICATION_XML_VALUE
        response?.writer?.append(sitemapService.createSitemap())
    }
}

@RestController
class SitemapController(@Autowired val sitemapView: SitemapView) {
    @GetMapping("/sitemap", produces = arrayOf(APPLICATION_XML_VALUE))
    fun generateSiteMap(): SitemapView {
        return sitemapView
    }
}
----

Pour g√©n√©rer le fichier *XML*, nous avons utilis√© cette librairie https://github.com/lgraubner/sitemap-generator.


== Niveau dur : faire un rendu serveur uniquement lors de l'appel par les robots

La derni√®re √©tape est la plus compliqu√©.
Il faut ajouter une logique au niveau du serveur front qui, si l'appel vient d'un robot, le redirige vers un service permettant de g√©n√©rer le code *HTML* final de notre page car le probl√®me des robots c'est que 1, ils n'aiment pas le javascript et 2, ils n'aiment pas attendre.

Le service en question que nous avons choisi se nomme *Rendertron* (https://github.com/GoogleChrome/rendertron). Ce n'est rien d'autre qu'un *Google Chrome* headless auquel on envoie l'url de la page que l'on d√©sire et nous renvoie le code HTML en r√©ponse.

Pour d√©cider si l'on doit faire du rendu c√¥t√© serveur ou du rendu c√¥t√© client, nous nous sommes inspir√© d'une librairie Java https://github.com/greengerong/prerender-java.
Cette librairie fournit directement un filtre HTTP permettant de rediriger vers une url si le `User-Agent` est compris dans la liste des robots de crawling.

Il nous a suffit de brancher ce filtre au niveau de Spring Boot comme ceci :


[source, java]
----
@Bean
public FilterRegistrationBean registerSeoFilter() {
    PreRenderSEOFilter seoFilter = new PreRenderSEOFilter();
    FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean();

    filterRegistrationBean.setFilter(seoFilter);
    filterRegistrationBean.addInitParameter(
        "prerenderServiceUrl",
        env.getProperty("application.rendertron.url")+"/render");

    filterRegistrationBean.addUrlPatterns("/*");

    return filterRegistrationBean;
}
----

== Tests

Une fois que vous avez fait toutes vos modifications, vous pouvez tester le bon fonctionnement gr√¢ce √† plusieurs outils :

* https://cards-dev.twitter.com/validator : le syst√®me de *Twitter* pour v√©rifier l'aper√ßu d'un lien quand on le partage dans un tweet.
* https://search.google.com/search-console : la *Google Search Console*, l'outil de *Google* vous permet de voir le *HTML* ou m√™me une capture d'√©cran d'une URL de votre site de la fa√ßon dont voit le robot d'indexation de *Google*. Il vous permet aussi de consulter le sitemap et voir si ses urls ont bien √©t√© index√©es.

Enfin vous n'avez plus qu'√† attendre quelques jours que les diff√©rents robots passent sur votre site afin de voir les r√©sultats sur les diff√©rents moteurs de recherche.